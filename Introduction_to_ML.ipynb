{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"vs.png\" style=\"width:600px;height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "       1). What is machine learning?\n",
    "            Machine learning is all about extracting patterns from data.\n",
    "            Definition: It enables machine to automatically learn from data,improves performance from experiences\n",
    "                    and predict things without being explicitly programmed.\n",
    "                    \n",
    "       2). why to use machin learning?\n",
    "            Explicit programming cons:\n",
    "             1. The logic required to make a decision is specific to a single domain and task.\n",
    "                Changing the task even slightly might require a rewrite of the whole system\n",
    "             2. Designing rules requires a deep understanding of how a decision should be made by a human expert.\n",
    "             \n",
    "             ML easily addresses the above problems.\n",
    "        \n",
    "       3). where to use machin learning?\n",
    "            It is been widely used in many industries like mdeial,retail,survilence etc..\n",
    "                Ex:Google translation,self driving cars,Alexa,Siri,recommendation systems....\n",
    "                \n",
    "       4). when to use machine learning?\n",
    "            When we need to predict the generalized patterns not for memorizing the answers.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   How Does Machine Learning work ?\n",
    "       . Learns from Historical data \n",
    "       . Builds prediction models (finding a mathematical equation to map the input data to the output)\n",
    "       . predict the output when we recieve new data.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"how.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    Terms:\n",
    "     Labeled Data:\n",
    "         History data with one or more columns labeled as output\n",
    "     Features:\n",
    "         input/output Columns of the data\n",
    "     Independent features/predictor: \n",
    "         input columns of the data\n",
    "     Dependent features/Labels/target: \n",
    "         output columns of the data\n",
    "     Dataset: Collection of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories of machine learning:\n",
    "        Category 1: Whether or not trained with supervision (supervized,unsupervized,reinforcement).\n",
    "        Category 2: Whether or not they can learn incrementally on the fly (online versus batch learning).\n",
    "        Category 3: Whether they work by simply comparing new data points to known data points(instance-based vsmodel-based)\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"types.png\" style=\"width:400px;height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning:\n",
    "    A machine learning method in which we provide the labeled data (input/output pairs) in order to train it, find mathematical function and predict the output using it.\n",
    "    \n",
    "    Under the supervision of history data, model will be trained.We do have pre-determined results.\n",
    "    \n",
    "    Categorized into:\n",
    "        1). Classification:\n",
    "        2). Regression\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning:\n",
    "    Unsupervised learning is a learning method in which a machine learns without any history data (supervision with labels).\n",
    "    \n",
    "    We dont have pre-determined results.\n",
    "    \n",
    "    Categorized into:\n",
    "        1) Clustering\n",
    "        2) Association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Leanring:\n",
    "Reinforcement learning is a feedback-based learning method, in which a learning agent gets a reward for each right action and gets a penalty for each wrong action. The agent learns automatically with these feedbacks and improves its performance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semisupervised learning is with few labeled and few unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Supervised Learning:\n",
    "        > Labeled Data \n",
    "        > Direct Feedback\n",
    "        > Predict Outcome\n",
    "\n",
    "    Unsupervised Learning:\n",
    "        > No Labels\n",
    "        > No Feedback\n",
    "        > Find hidden structure in data\n",
    "\n",
    "    Reinforcement Learning:\n",
    "        > Decision Process\n",
    "        > Reward Process\n",
    "        > Learn series of actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category 2:\n",
    "\n",
    "     Batch Learning (offline learning): \n",
    "     \n",
    "         The system is trained on full available data and then launch it into production, runs without learning anymore.   \n",
    "         To a new data to be trained,we need to train full system on the available dataset.\n",
    "           Simply update data and train new version of data from scratch\n",
    "       \n",
    "          Pros: simple and often used\n",
    "          cons: more resources required to train on complete dataset (in case of huge dataset)\n",
    "                system shd get trained frequently for rapid chaging data\n",
    "        \n",
    "      Online Learning (Incremental Learning):\n",
    "            The system is trained incrementally on the fly\n",
    "          Pros: Fast and cheap.\n",
    "          Cons: wont be more accurate as it trains on every instance\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category 3:\n",
    "    \n",
    "    Instance based :\n",
    "        System learns from the data and generalize the new data.Like finding similarity of such instances and assign that class.\n",
    "    Model Based: Build a model to generalize and model predicts the new data class.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main steps of Machine learning:\n",
    "        Step 1: Data collection\n",
    "        Step 2: Data preprocessing/Data wrangling/Feature Engineering.\n",
    "        Step 3: Data analysis (Exploratory data analysis)\n",
    "        Step 4: Choose a model\n",
    "        Step 6: Train the model\n",
    "        Step 7: Evaluate the model\n",
    "        Step 8: Parameter tuning\n",
    "        Step 9: Prediction and deployement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collection\n",
    "     At high level, data is of two types:\n",
    "         1) Numerical data:\n",
    "             . Continuous or quantitative: Any real number.Ex: stock price,weather forecasting             \n",
    "             \n",
    "         2) Categorical data (text/string):\n",
    "             . Discrete or qualitative: \n",
    "                  Nominal: Green or Red or Yellow,Yes or No, Male or Female\n",
    "                  Ordinal: Small or medium or large\n",
    "      \n",
    "      Data is most commonly available in formats csv,xls,json.It is either provided by customers or can be taken from online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing/Data wrangling/Feature Engineering:\n",
    "\n",
    "   1. Getting the dataset\n",
    "   2. Importing libraries\n",
    "   3. Importing datasets and extract independent and dependent features\n",
    "   4. Handling Missing Data (optional , depends on ur dataset)\n",
    "   5. Encoding Categorical Data (optional , depends on ur dataset)\n",
    "   6. Splitting dataset into training and test set\n",
    "   7. Feature scaling (optional , depends on ur dataset)\n",
    "   8. Feature selection/ extraction (optional , depends on ur dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 to step 3:\n",
    "    # importing libraries  \n",
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp  \n",
    "import pandas as pd  \n",
    "  \n",
    "#importing datasets  \n",
    "data_set= pd.read_csv('Dataset.csv')  \n",
    "  \n",
    "#Extracting Independent Variable  \n",
    "x= data_set.iloc[:, :-1].values  \n",
    "\n",
    "#Extracting Dependent variable  \n",
    "y= data_set.iloc[:, 3].values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Step 4:Handling with Missing Data:   \n",
    "            1 > Delete:\n",
    "                        Delete the rows or columns having the missing values. This approach is better \n",
    "                        when the number  of missing values rows count is < 5%.                       \n",
    "            2 > Replace with summary:\n",
    "                            Most commonly used imputation technique.Summary means mean (average) or mode or median \n",
    "                                     Numerical data: Mean or median\n",
    "                                     Categorical data: Mode\n",
    "            3 > Random Replace: Randomly pick values from that respective column and replace it.This is used when \n",
    "                                missing value row count is insignificant.\n",
    "            4 > Predictive model: This is advanced technique where model predicts the missing value.\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to check if df has missing values\n",
    "  #isnull() or isna()\n",
    "\n",
    "# practical code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "                   \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "                   \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
    "                            pd.NaT]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting:\n",
    "\n",
    "#Drop rows where atlease one element is missing\n",
    "print(df.dropna())\n",
    "#print(df)\n",
    "\n",
    "#Drop columns where atlease one element is missing\n",
    "print(df.dropna(axis=1))  \n",
    "# or \n",
    "print(df.dropna(axis='columns'))\n",
    "\n",
    "# Drop the rows where all elements are missing\n",
    "print(df.dropna(how='all'))\n",
    "\n",
    "# keep the rows only when atleast two non- na values present\n",
    "print(df.dropna(thresh=3))\n",
    "\n",
    "# IF we need to look after specific columns\n",
    "print(df.dropna(subset=['name']))\n",
    "\n",
    "# If we want the changes to be done to original data then use inplace=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace with summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      col1  col2  col3\n",
      "row1   2.0   6.5   3.0\n",
      "row2   2.0   NaN   NaN\n",
      "row3   NaN   6.5   NaN\n",
      "row4   NaN   6.5   4.0\n"
     ]
    }
   ],
   "source": [
    "# will use fillna()\n",
    "from numpy import nan as NA\n",
    "\n",
    "data = pd.DataFrame([[2., 6.5, 3.], [2., np.nan,NA], [NA, 6.5, NA], [NA, 6.5, 4]]\n",
    "                    ,columns=['col1','col2','col3']\n",
    "                    ,index=['row1','row2','row3','row4'])\n",
    "\n",
    "data1 = pd.DataFrame([[5., 7.5, 3.], [2., np.nan,NA], [NA, 7.5, NA], [NA, 6.5, 6]]\n",
    "                    ,columns=['col1','col2','col3']\n",
    "                    ,index=['row1','row2','row3','row4'])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with constant\n",
    "print(data.fillna(value=1))\n",
    "\n",
    "# Replace with different fill value for each column:\n",
    "print(data.fillna({1:0.5,2:0.7}))\n",
    "\n",
    "# Replace with previous value, we can limit the number of fillings using limit\n",
    "print(data.fillna(method='ffill'))\n",
    "print(data.fillna(method='ffill',limit=1))\n",
    "\n",
    "# Replace with next value, we can limit the number of fillings using limit\n",
    "print(data.fillna(method='bfill'))\n",
    "print(data.fillna(method='bfill',limit=1))\n",
    "\n",
    "# Replace with mean\n",
    "print(data.fillna(data.mode()))\n",
    "\n",
    "# to affect the orginal data, we shd use inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.  6.5 3. ]\n",
      " [2.  6.5 3. ]\n",
      " [2.  6.5 3. ]\n",
      " [2.  6.5 4. ]]\n"
     ]
    }
   ],
   "source": [
    "# Another way of replacing is with scikit learn estimator API Simple Imputer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imr=SimpleImputer(missing_values=np.nan,strategy='most_frequent') # strategy can be either mean,median,mode\n",
    "imr_fit=imr.fit(data.values)  \n",
    "data=imr_fit.transform(data.values)\n",
    "print(data)\n",
    "# print(imputed)\n",
    "\n",
    "\n",
    "# Note: fit finds the mean of columns and transform converts it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Replace with random values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(NA,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'], 'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "df1['k1'].drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below method returns booleabs values if a row is duplicate or not\n",
    "#print(df1.duplicated())\n",
    "\n",
    "# to drop duplicate rows where all elements in columns are same\n",
    "#print(df1.drop_duplicates())\n",
    "\n",
    "# to drop duplicate rows where all elements in specific columns are same\n",
    "print(df1.drop_duplicates(['k1']))\n",
    "\n",
    "# basically drop will keep first occurence and delete the rest duplicates, if u want to keep last occurence then\n",
    "#print(df1.drop_duplicates(['k1'],keep='last'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #### Difference between fit (), transform(),fit_transform() and predict()\n",
    "    Transformers: Used for data preprocessing . Ex: SimpleImputer class and feature selection class.\n",
    "        1. fit (): Used to find the parameters (mean,median,mode) values of the training data and saves the state internally\n",
    "        2. transform(): Use the above calculated mean and return the modified data.\n",
    "        3. fit_transform(): use fit() first and trasnform() second.\n",
    "        \n",
    "    Model: used to make predictions with models like linear regression etc.,\n",
    "        1. fit(): Used to calculate the parameters/weights/coefficients on training data\n",
    "        2. predict(): Use the above calculated weights to make the predictions.\n",
    "        3. transform(): cannot be used\n",
    "        4. fit_transform(): cannot be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Encoding categorical data:\n",
    "    Categorical Data: Many ML algorithms need categorical daat to be encoded to integer values.\n",
    "    \n",
    "                  1. Ordinal : where values can be ordered /sorted.\n",
    "                  2. Nominal : where values cannot be ordered /sorted\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class2\n",
       "1    red    L   13.1     class1\n",
       "2   blue   XL   15.3     class2"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(\n",
    "                [\n",
    "                  ['green','M',10.1,'class2']  ,\n",
    "                  ['red','L',13.1,'class1'] ,\n",
    "                  ['blue','XL',15.3,'class2']\n",
    "                ]\n",
    "               )\n",
    "df.columns=['color','size','price','classlabel']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Ordinal Data:\n",
    "     Map a unique numbers manually inorder to preserve the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class2\n",
       "1    red     2   13.1     class1\n",
       "2   blue     3   15.3     class2"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_dict={\n",
    "            'M':1,\n",
    "            'L':2,\n",
    "            'XL':3\n",
    "            }\n",
    "df['size']=df['size'].map(size_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### Handling Nominal Data: No need to preserve the order. \n",
    "    Approach 1:\n",
    "        1. Lable Encoding: Assigns unique number to every categorical value.\n",
    "        2. One hot encoding: Creates new dummy features to the categorical values and uses binary values to represent value.\n",
    "    Approach 2:\n",
    "        1. get_dummies function converts all string columns without touching  numerical columns.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0      1     1   10.1     class2\n",
       "1      2     2   13.1     class1\n",
       "2      0     3   15.3     class2"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding using sckit learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['color']=le.fit_transform(df['color'].values)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Problem with label encoding: After applying label encoding, nominal data looks like preserving some order (color column) \n",
    "                                which gives wrong results\n",
    "    Solution: Use one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-hot encoding:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe=OneHotEncoder()\n",
    "X=df[['color','size','price']].values\n",
    "ohe.fit_transform(X[:,0].reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, 'M', 10.1],\n",
       "       [0.0, 0.0, 1.0, 'L', 13.1],\n",
       "       [1.0, 0.0, 0.0, 'XL', 15.3]], dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe=OneHotEncoder()\n",
    "X=df[['color','size','price']].values\n",
    "#ohe.fit_transform(X[:,0].reshape(-1,1)).toarray()\n",
    "\n",
    "# We are applying to one column, so we converted it to vector using reshape\n",
    "\n",
    "# If we want to apply multiple columns we can use sklearn library ColumnTransfer as below:\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct=ColumnTransformer(\n",
    "                        [\n",
    "                            ('onehot',OneHotEncoder(),[0]),\n",
    "                            ('nothing','passthrough',[1,2])\n",
    "                        ]\n",
    "                    )\n",
    "X=ct.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Problem with one hot encoding: with one hot encoding, features become highly correlated \n",
    "                            which makes matrix inversion difficult.This problem is called multi collinearity.\n",
    "    Solution: We can remove one feature to reduce it. Use drop='first',categories='auto' options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In order to solve multicollinearity with one hot enoding use below options:\n",
    "X=df[['color','size','price']].values\n",
    "color_ohe=OneHotEncoder(drop='first',categories='auto')\n",
    "ct=ColumnTransformer(\n",
    "                        [\n",
    "                            ('onehot',OneHotEncoder(categories='auto',drop='first'),[0]),\n",
    "                            ('nothing','passthrough',[1,2])\n",
    "                        ]\n",
    "                    )\n",
    "X=ct.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Approach 2: get_dummies function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "      <th>classlabel_class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color_green  color_red  classlabel_class2\n",
       "0            1          0                  1\n",
       "1            0          1                  0\n",
       "2            0          0                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(\n",
    "                [\n",
    "                  ['green','M',10.1,'class2'],\n",
    "                  ['red','L',13.1,'class1'],\n",
    "                  ['blue','XL',15.3,'class2']\n",
    "                ]\n",
    "               )\n",
    "df.columns=['color','size','price','classlabel']\n",
    "pd.get_dummies(df[['color','classlabel']],drop_first=True)\n",
    "\n",
    "# To reduce multicollinearity , use drop_first=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Splitting the Dataset into the Training set and Test set:\n",
    "\n",
    "In machine learning data preprocessing, we divide our dataset into a training set and test set. This is one of the crucial steps of data preprocessing as by doing this, we can enhance the performance of our machine learning model\n",
    "\n",
    "##### Make sure the features are splitted into two arrays independent and depenedent \n",
    "\n",
    "    X=df.iloc[:,:-1].values, y=df.iloc[:,3].values\n",
    "    from sklearn.model_selection import train_test_split  \n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0,stratify=y) \n",
    "\n",
    "    1) In the above code, the first line is used for splitting arrays of the dataset into random train and test subsets.\n",
    "    2) In the second line, we have used four variables for our output that are\n",
    "        x_train: features for the training data\n",
    "        x_test: features for testing data\n",
    "        y_train: Dependent variables for training data\n",
    "        y_test: Independent variable for testing data\n",
    "    3) In train_test_split() function, we have passed four parameters in which first two are for arrays of data,\n",
    "        and test_size is for specifying the size of the test set. The test_size maybe .5, .3, or .2, which tells the \n",
    "        dividing ratio of training and testing sets.\n",
    "    4) The last parameter random_state is used to set a seed for a random generator so that you always get the same result, and the most used value for this is 42.\n",
    "    5) with stratify option, training and test datasets will have same class proportions as the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 : Feature scaling:\n",
    "\n",
    "##### Why should we use feature scaling?\n",
    "     Most of the ML agorithms uses Gradient descent to obtain parameters which requires data to be scaled.\n",
    "  ###### Having features on a similar scale can help the gradient descent converge more quickly towards the minima\n",
    "\n",
    "##### what is feature scaling ?\n",
    "    It is a technique to convert the feature values in the same range and in the same scale so that no any variable dominate the other variable.\n",
    "\n",
    "    There are three ways to perform feature scaling in machine learning:\n",
    "###### Standardization:\n",
    "                    Rescales the features values and centers the values around 0 mean and 1 standard deviation\n",
    "                    This makes easier to learn weights and also less sensitive to outliers.\n",
    "                    This is most commonly used techinique.\n",
    "                    \n",
    "                    Usage: Use when data isfollowing guassian distribution.\n",
    "                    equation: xi_new =x_old − mean(x)/standard deviation\n",
    "###### Normalization/min-max scaling:\n",
    "        Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.Rescale the feature values between 0 and 1\n",
    "                    \n",
    "                    Usage: Use when data is not following guassian distribution.\n",
    "                    equation: xi_new =x_old − min(x)/max(x) − min(x)\n",
    "    \n",
    "###### Robust Scaler:\n",
    "        is used when we have small datasets and more outliers.\n",
    "    \n",
    "      # Standardization:\n",
    "        from sklearn.preprocessing import StandardScaler  \n",
    "        st_x= StandardScaler()  \n",
    "        x_train= st_x.fit_transform(x_train)  \n",
    "        x_test= st_x.transform(x_test)  \n",
    "      # Normalization:\n",
    "        from sklearn.preprocessing import MinMaxScaler  \n",
    "        st_x= MinMaxScaler()  \n",
    "        x_train= st_x.fit_transform(x_train)  \n",
    "        x_test= st_x.transform(x_test)  \n",
    "###### Distance based algorithms like KNN, K-means and SVM are most affected by the range of features. Because, these use euclidean distance between data points to find the similarity.    \n",
    "###### Tree based algorithms like decision trees and random forests are invariant to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[(lambda x:x*2)(x) for x in range(5)]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bf93bc23fd47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ab'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = ['ab','cd']\n",
    "for i in x:\n",
    "    x.append(i.upper())\n",
    "print(x)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
